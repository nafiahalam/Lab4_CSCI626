{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQtm8ra5wlQL",
        "outputId": "3cc9ded7-bcc6-4abd-e806-41d9abe329c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy import stats\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "t8hbpZqLwo9V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer, StringIndexer, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from pyspark.ml.clustering import KMeans"
      ],
      "metadata": {
        "id": "IKAM7UTjG5R5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to install and set up PySpark for use\n",
        "!pip install -q findspark\n",
        "!pip install -q pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Create a Spark session to run KNN\n",
        "spark_sess = SparkSession.builder.appName(\"Colab\").getOrCreate()\n",
        "spark_sess = SparkSession.builder.appName(\"KNN_Classifier\").getOrCreate()"
      ],
      "metadata": {
        "id": "vyb-Te_xFTkU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the Directory to data folder present in the system\n",
        "%cd /content/sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX6FZ3abFiPo",
        "outputId": "6ca56b46-f53c-4f8b-9b16-91d79dd4b00f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data1 = spark_sess.read.option(\"header\", \"true\").csv('/content/sample_data/gender_submission.csv', inferSchema=True)"
      ],
      "metadata": {
        "id": "Wl3DjbZ8GToY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "training_data1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR2FgZipGe5i",
        "outputId": "0481138d-ddfb-4729-fd11-79deab08468a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+\n",
            "|PassengerId|Survived|\n",
            "+-----------+--------+\n",
            "|        892|       0|\n",
            "|        893|       1|\n",
            "|        894|       0|\n",
            "|        895|       0|\n",
            "|        896|       1|\n",
            "|        897|       0|\n",
            "|        898|       1|\n",
            "|        899|       0|\n",
            "|        900|       1|\n",
            "|        901|       0|\n",
            "|        902|       0|\n",
            "|        903|       0|\n",
            "|        904|       1|\n",
            "|        905|       0|\n",
            "|        906|       1|\n",
            "|        907|       1|\n",
            "|        908|       0|\n",
            "|        909|       0|\n",
            "|        910|       1|\n",
            "|        911|       1|\n",
            "+-----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In this section, we are splitting the data into both the training and the testing data. We will considering 80% of the data for training and the remaining 20% for testing.\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler_sess = VectorAssembler(\n",
        "    inputCols=[\"Pclass_scaled\", \"Age_scaled\", \"SibSp_scaled\", \"Parch_scaled\", \"Fare_scaled\", \"Sex_indexed_scaled\"],\n",
        "    outputCol=\"input_features\"\n",
        ")\n",
        "\n",
        "scaling_data1 = scaling_data1.drop(*[feature + '_mean' for feature in numeric_columns] + [feature + '_std' for feature in numeric_columns])\n",
        "assembled_data = assembler_sess.transform(scaling_data1)\n",
        "training_data, test_data = assembled_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Display the number of rows in each set\n",
        "print(\"Training set count:\", training_data1.count())\n",
        "print(\"Testing set count:\", test_data.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "odUL3kamG2ad",
        "outputId": "3ddba1ee-c889-4f74-a1a8-b62cf4b91daa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7d2a9ad71222>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mscaling_data1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_mean'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_std'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0massembled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaling_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaling_data1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HloeQ3IzICyh",
        "outputId": "422d17ba-f3f3-4510-b3a0-803a448cd3c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Utilizing the Pandas Dataframe\n",
        "pandas_features = scaling_data1.toPandas()\n",
        "\n",
        "# We are defining the features used in both x and y\n",
        "X = pandas_features[['Pclass_scaled', 'Age_scaled', 'SibSp_scaled', 'Parch_scaled', 'Fare_scaled', 'Sex_indexed_scaled']]\n",
        "y = pandas_features['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "knn_classifier1 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_classifier1.fit(X_train, y_train)\n",
        "\n",
        "y_predications = knn_classifier1.predict(X_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_test, y_predications)\n",
        "print(f\"Accuracy: {accuracy_sc:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "RGuREd-QIFST",
        "outputId": "f63aa785-6e46-4a7a-998b-b6747feed450"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b126041f9731>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert Spark DataFrame to Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpandas_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling_data1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaling_data1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# We are going to determine the K values for the KNN algorithm in this step:\n",
        "X = scaling_data1.select(\"Age_scaled\", \"SibSp_scaled\", \"Parch_scaled\", \"Fare_scaled\").toPandas()\n",
        "y = scaling_data1.select(\"Survived\").toPandas()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "k_values1 = list(range(1, 21)))\n",
        "\n",
        "accuracy_scores = []\n",
        "\n",
        "for k in k_values1:\n",
        "    # Create a KNN classifier with the current K value\n",
        "    knn_alg = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Perform 5-fold cross-validation\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    accuracy_scores_kfold = cross_val_score(knn_alg, X, y.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "\n",
        "    # Record mean accuracy\n",
        "    accuracy_mean = np.mean(accuracy_scores_kfold)\n",
        "    accuracy_scores.append(accuracy_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "GFe8eFkDJQ6G",
        "outputId": "fa0e52ad-63fe-43bf-9383-b7a9a5c4ee61"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-3928fa14a6fd>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    k_values1 = list(range(1, 21)))\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ]
    }
  ]
}